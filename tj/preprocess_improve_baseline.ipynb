{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfba5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import itertools\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bokeh.io import output_notebook, show, save\n",
    "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine, EdgesAndLinkedNodes, NodesAndLinkedEdges, LabelSet\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.plotting import from_networkx\n",
    "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8\n",
    "from bokeh.transform import linear_cmap\n",
    "from networkx.algorithms import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa08f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './final_proj/'\n",
    "files = sorted(os.listdir(path))\n",
    "N = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa18d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_words = {}\n",
    "for j in tqdm(range(N)):\n",
    "    with open(path + files[j]) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    num_blocks = len(data['result']['blocks'])\n",
    "    extracted_words_set = set()\n",
    "    \n",
    "    for i in range(num_blocks):\n",
    "        if data['result']['blocks'][i]['type'] == 'text' or data['result']['blocks'][i]['type'] == 'header':\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'«[\\w]+»', data['result']['blocks'][i]['data']['text'])))\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'\"[\\w]+\"', data['result']['blocks'][i]['data']['text'])))\n",
    "            #print(re.findall(r'[\\s]?[A-Z][A-Za-z]+[\\s]|[\\s]?[А-Я][А-Яа-я]+[\\s]', data['result']['blocks'][i]['data']['text']))\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'[A-Z][A-Za-z]*[\\.][A-Z][A-Za-z]*|[А-Я][А-Яа-я]*[\\.][А-Я][А-Яа-я]*', data['result']['blocks'][i]['data']['text'])))\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'[A-Z]+[^a-z]|[А-Я]+[^а-я]', data['result']['blocks'][i]['data']['text'])))\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'[A-Z][a-z]+|[А-Я][а-я]+', data['result']['blocks'][i]['data']['text'])))\n",
    "            \n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'[A-Z][a-z]+[\\s-][A-Z][a-z]+|[А-Я][а-я]+[\\s-][А-Я][а-я]+', data['result']['blocks'][i]['data']['text'])))\n",
    "            extracted_words_set = extracted_words_set.union(set(re.findall(r'[A-Z][a-z]+\\s&\\s[A-Z][a-z]+|[A-Z][a-z]+&[A-Z][a-z]+', data['result']['blocks'][i]['data']['text'])))\n",
    "\n",
    "    extracted_words[files[j]] = [item.lower().strip('«.» ,') for item in extracted_words_set]\n",
    "    #        print(data['result']['blocks'][i]['data']['text'].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc3c3379",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mapa_comp.pkl', 'rb') as f:\n",
    "    mapa = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83321b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('companies_stopwords.txt', 'r') as f:\n",
    "    stop_words_comp = f.read()\n",
    "stop_words_comp = set(stop_words_comp.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "e1d3dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('companies_habr_upd.txt', 'r') as f:\n",
    "    companies_habr = f.read()\n",
    "companies_habr = set(companies_habr.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "5e664a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('companies_vc_upd.txt', 'r') as f:\n",
    "    companies_vc = f.read()\n",
    "companies_vc = set(companies_vc.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "f17aad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('companies_add.txt', 'r') as f:\n",
    "    companies_add = f.read()\n",
    "companies_add = set(companies_add.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "42fda72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = companies_habr.union(companies_vc).union(companies_add) - stop_words_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "0b7a683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_w2 = set(['tj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "d16cddd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 298694/298694 [00:01<00:00, 219688.04it/s]\n"
     ]
    }
   ],
   "source": [
    "extracted_companies = {}\n",
    "for key in tqdm(extracted_words.keys()):\n",
    "    for word in extracted_words[key]:\n",
    "        if (word in companies) and (not word in stop_w2) and ((not word in mapa.keys()) or  ((word in mapa.keys()) and (not mapa[word] in stop_w2))):\n",
    "            if not key in extracted_companies.keys():\n",
    "                extracted_companies[key] = []\n",
    "            if word in mapa.keys():\n",
    "                extracted_companies[key].append(mapa[word])\n",
    "            else:\n",
    "                extracted_companies[key].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "0123a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in extracted_companies.keys():\n",
    "    extracted_companies[key] = list(set(extracted_companies[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "id": "a1614b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 2500)\n",
    "extracted_companies_ = {}\n",
    "for key in extracted_companies.keys():\n",
    "    extracted_companies_[key] = ';'.join(extracted_companies[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "e2e52d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['companies'] = df['companies'].str.split(';')\n",
    "#df = df.explode('companies')\n",
    "#df.groupby('companies').agg('count').sort_values('index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "bd2fa85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for key in extracted_companies.keys():\n",
    "    if len(extracted_companies[key]) > 1:\n",
    "        for element in itertools.product(*[extracted_companies[key], extracted_companies[key]]):\n",
    "            edges.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "a1838c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 245112/245112 [00:00<00:00, 590759.33it/s]\n"
     ]
    }
   ],
   "source": [
    "edges_ = {}\n",
    "for item in tqdm(edges):\n",
    "    if item[0] != item[1]:\n",
    "        if (not (item[0], item[1]) in edges_.keys()) and (not (item[1], item[0]) in edges_.keys()):\n",
    "            edges_[item] = 0.0\n",
    "        else:\n",
    "            if (item[0], item[1]) in edges_.keys():\n",
    "                edges_[item] += 1.0\n",
    "            elif (item[1], item[0]) in edges_.keys():\n",
    "                edges_[(item[1], item[0])] += 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "504a0444",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for key in edges_.keys():\n",
    "    if edges_[key] > 1:\n",
    "        G.add_weighted_edges_from([(key[0], key[1], edges_[key])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "31611e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = dict(networkx.degree(G))\n",
    "networkx.set_node_attributes(G, name='degree', values=degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "f1aaa8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_to_adjust_by = 3\n",
    "adjusted_node_size = dict([(node, 0.1*(degree+number_to_adjust_by)) for node, degree in networkx.degree(G)])\n",
    "networkx.set_node_attributes(G, name='adjusted_node_size', values=adjusted_node_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "b14c7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import community\n",
    "communities = community.greedy_modularity_communities(G, weight='weight', resolution=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "d5a5e6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "42ac8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dictionaries\n",
    "modularity_class = {}\n",
    "modularity_color = {}\n",
    "colors = (\n",
    "'#3288bd',\n",
    "'#66c2a5',\n",
    "'#abdda4',\n",
    "'#e6f598',\n",
    "'#fee08b',\n",
    "'#fdae61',\n",
    "'#f46d43',\n",
    "'#d53e4f',   \n",
    "'#8c2d04',\n",
    "'#8B3A62',\n",
    "'#EE2C2C',\n",
    "    \n",
    "'#BFEFFF',\n",
    "'#68838B',\n",
    "'#FFA07A',\n",
    "'#E066FF',\n",
    "'#5D478B',\n",
    "'#48D1CC',\n",
    "'#FFE4E1',\n",
    "    '#000080',\n",
    "    '#FFEFD5',\n",
    "    '#308014',\n",
    "    \n",
    "    '#7D9EC0',\n",
    "    '#C67171',\n",
    "    '#8B7B8B',\n",
    "    '#8B8B00',\n",
    "    '#838B8B',\n",
    "    '#8B8378',\n",
    "    '#8A360F',\n",
    "    '#C1FFC1',\n",
    "    \n",
    ")\n",
    "#Loop through each community in the network\n",
    "for community_number, community in enumerate(communities):\n",
    "    #For each member of the community, add their community number and a distinct color\n",
    "    for name in community: \n",
    "        modularity_class[name] = community_number\n",
    "        modularity_color[name] = colors[community_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "3bd92daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.set_node_attributes(G, modularity_class, 'modularity_class')\n",
    "networkx.set_node_attributes(G, modularity_color, 'modularity_color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "469aff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose colors for node and edge highlighting\n",
    "node_highlight_color = 'white'\n",
    "edge_highlight_color = 'black'\n",
    "edge_color = 'gray'\n",
    "\n",
    "#Choose attributes from G network to size and color by — setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "size_by_this_attribute = 'adjusted_node_size'\n",
    "color_by_this_attribute = 'modularity_color'\n",
    "\n",
    "#Pick a color palette — Blues8, Reds8, Purples8, Oranges8, Viridis8\n",
    "color_palette = Blues8\n",
    "\n",
    "#Choose a title!\n",
    "title = 'Companies graph'\n",
    "\n",
    "\n",
    "#Establish which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [\n",
    "       (\"Companies\", \"@index\"),\n",
    "        (\"Degree\", \"@degree\"),\n",
    "         (\"Modularity Class\", \"@modularity_class\"),\n",
    "      #  (\"Modularity Color\", \"$color[swatch]:modularity_color\"),\n",
    "]\n",
    "\n",
    "#Create a plot — set dimensions, toolbar, and title\n",
    "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
    "\n",
    "#Create a network graph object\n",
    "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
    "network_graph = from_networkx(G, networkx.spring_layout, scale=10, center=(0, 0))\n",
    "\n",
    "#Set node sizes and colors according to node degree (color as category from attribute)\n",
    "network_graph.node_renderer.glyph = Circle(size=size_by_this_attribute, fill_color=color_by_this_attribute)\n",
    "\n",
    "\n",
    "\n",
    "#Set node highlight colors\n",
    "network_graph.node_renderer.hover_glyph = Circle(size=size_by_this_attribute, fill_color=node_highlight_color, line_width=2)\n",
    "network_graph.node_renderer.selection_glyph = Circle(size=size_by_this_attribute, fill_color=node_highlight_color, line_width=2)\n",
    "\n",
    "#Set edge opacity and width\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.3, line_color=edge_color, line_width=1)\n",
    "#Set edge highlight colors\n",
    "network_graph.edge_renderer.selection_glyph = MultiLine(line_color=edge_highlight_color, line_width=2)\n",
    "network_graph.edge_renderer.hover_glyph = MultiLine(line_color=edge_highlight_color, line_width=2)\n",
    "\n",
    "#Highlight nodes and edges\n",
    "network_graph.selection_policy = NodesAndLinkedEdges()\n",
    "network_graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "#Add Labels\n",
    "x, y = zip(*network_graph.layout_provider.graph_layout.values())\n",
    "node_labels = list(G.nodes())\n",
    "source = ColumnDataSource({'x': x, 'y': y, 'name': [node_labels[i] for i in range(len(x))]})\n",
    "labels = LabelSet(x='x', y='y', text='name', source=source, background_fill_color='white', text_font_size='10px', background_fill_alpha=.7)\n",
    "plot.renderers.append(labels)\n",
    "\n",
    "show(plot)\n",
    "#save(plot, filename=f\"{title}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "b801a1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(G.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76acd7",
   "metadata": {},
   "source": [
    "## Find close companies via Jaccard score of neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "d141e23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 924/924 [00:40<00:00, 23.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "attr_relevant_nodes = defaultdict(list)\n",
    "for i in tqdm(range(len(node_list))):\n",
    "    adamic = {}\n",
    "    for j in range(len(node_list)):\n",
    "        if i != j:\n",
    "            res = list(nx.jaccard_coefficient(G, [(node_list[i], node_list[j])]))[0]\n",
    "            adamic[(res[0], res[1])] = res[2]\n",
    "    relevant_nodes = list(sorted(adamic.items(), key=lambda item: item[1], reverse=True))[:10]\n",
    "    for k in range(len(relevant_nodes)):\n",
    "        attr_relevant_nodes[relevant_nodes[k][0][0]].append(relevant_nodes[k][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "4093eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.set_node_attributes(G, attr_relevant_nodes, 'relevant_nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48f7ecd",
   "metadata": {},
   "source": [
    "# Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "25fe03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_companies = pd.read_csv('./tj_data/df_companies.csv')\n",
    "df_info = pd.read_csv('./tj_data/df_info.csv')\n",
    "#df_texts = pd.read_csv('./tj_data/df_texts.csv')\n",
    "df_sentiment = pd.read_csv('./tj_data/tj_average_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "4a3e163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_comp.to_csv('tj_comp_upd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "52775e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.DataFrame(extracted_companies_, index=[0]).T.reset_index().rename({0: 'companies'}, axis=1)\n",
    "df_companies['companies'] = df_companies['companies'].str.split(';')\n",
    "df_companies = df_companies.explode('companies').rename({'index': 'doc_id'},axis=1)#.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "id": "854535f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000000004</td>\n",
       "      <td>samsung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000000015</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000000018</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000000020</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000000031</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55847</th>\n",
       "      <td>0000449990</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55847</th>\n",
       "      <td>0000449990</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55847</th>\n",
       "      <td>0000449990</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55848</th>\n",
       "      <td>0000449991</td>\n",
       "      <td>instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55848</th>\n",
       "      <td>0000449991</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96911 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           doc_id  companies\n",
       "0      0000000004    samsung\n",
       "1      0000000015      apple\n",
       "2      0000000018      apple\n",
       "3      0000000020      apple\n",
       "4      0000000031     google\n",
       "...           ...        ...\n",
       "55847  0000449990    twitter\n",
       "55847  0000449990   facebook\n",
       "55847  0000449990  instagram\n",
       "55848  0000449991  instagram\n",
       "55848  0000449991   facebook\n",
       "\n",
       "[96911 rows x 2 columns]"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "id": "ca7dcaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment['post_id'] = df_sentiment['post_id'].astype(int)\n",
    "df_companies['doc_id'] = df_companies['doc_id'].astype(int)\n",
    "\n",
    "\n",
    "df_companies_sent = df_companies.merge(df_sentiment, how='left', left_on='doc_id', right_on='post_id')#.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "0235731e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>companies</th>\n",
       "      <th>post_id</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>skip</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82929</th>\n",
       "      <td>364655</td>\n",
       "      <td>aviator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id companies  post_id  neutral  negative  positive  skip  speech\n",
       "82929  364655   aviator      NaN      NaN       NaN       NaN   NaN     NaN"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_companies_sent[df_companies_sent['companies']=='aviator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "id": "eb2a0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sent = df_companies_sent.groupby('companies').agg({'neutral':'mean', 'negative': 'mean', 'positive': 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "d18b251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sent = comp_sent[comp_sent['companies'].isin(set(node_list))].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "9cf51b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_sent.to_csv('tj_sent_upd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutr = {}\n",
    "neg = {}\n",
    "pos = {}\n",
    "for i in range(len(comp_sent)):\n",
    "    neutr[comp_sent.iloc[i]['companies']] = comp_sent.iloc[i]['neutral']\n",
    "    neg[comp_sent.iloc[i]['companies']] = comp_sent.iloc[i]['negative']\n",
    "    pos[comp_sent.iloc[i]['companies']] = comp_sent.iloc[i]['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cca694",
   "metadata": {},
   "outputs": [],
   "source": [
    "networkx.set_node_attributes(G, neutr, 'neutral')\n",
    "networkx.set_node_attributes(G, neg, 'negative')\n",
    "networkx.set_node_attributes(G, pos, 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx.write_gpickle(G, \"G_tj_upd.gpickle\")\n",
    "#nx.write_gml(G, \"G_tj_upd_upd.gml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a15181",
   "metadata": {},
   "source": [
    "# Posts info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "90ac4ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 298694/298694 [10:46<00:00, 461.72it/s]\n"
     ]
    }
   ],
   "source": [
    "info = {}\n",
    "texts = {}\n",
    "#extracted_companies_str = {}\n",
    "#extracted_companies_keys = sorted(extracted_companies.keys())\n",
    "for key in tqdm(files):\n",
    "    with open(path + key) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    info[key] = {}\n",
    "    info[key]['post_id'] = data['result']['id']\n",
    "    info[key]['auth_id'] = data['result']['author']['id']\n",
    "    info[key]['commentsCount'] = data['result']['commentsCount']\n",
    "    info[key]['hitsCount'] = data['result']['hitsCount']\n",
    "    info[key]['likes'] = data['result']['likes']['count']\n",
    "    info[key]['year'] = data['result']['dateRFC'].split()[3]\n",
    "    #info[key]['tag'] = data['result']['subsite']['name']\n",
    "    #extracted_companies_str[key] = ';'.join(extracted_companies[key])\n",
    "    num_blocks = len(data['result']['blocks'])\n",
    "    extracted_words_set = set()\n",
    "    texts[key] = ''\n",
    "    for i in range(num_blocks):\n",
    "        if data['result']['blocks'][i]['type'] == 'text' or data['result']['blocks'][i]['type'] == 'header':\n",
    "            texts[key] += data['result']['blocks'][i]['data']['text']\n",
    "        texts[key] += ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "10f1285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info = (pd.DataFrame.from_dict(info).T).reset_index().rename({'index': 'doc_id'}, axis=1)\n",
    "#df_info.to_csv('tj_info_upd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "57530ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info['doc_id'] = df_info['doc_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "042180d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies_info = df_companies.merge(df_info, how='left', on='doc_id').groupby('companies').agg({'commentsCount':'mean', 'hitsCount': 'mean', 'likes': 'mean'}).reset_index()#.to_csv('companies_likes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "c7f394f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies_info = df_companies_info[df_companies_info['companies'].isin(set(node_list))].fillna(0)\n",
    "df_companies_info.to_csv('tj_upd_likes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c2f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147dd529",
   "metadata": {},
   "source": [
    "# Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "6ae3df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = (pd.DataFrame(texts, index=[0]).T).reset_index().rename({0:'text', 'index': 'doc_id'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "id": "5302e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_texts(df):\n",
    "    df = df['text']\n",
    "    df = re.sub(r'\\(http[\\S]*\\)', '', df)\n",
    "    df = re.sub(r'\\n', '', df)\n",
    "    df = re.sub(r'\\[', '', df)\n",
    "    df = re.sub(r'\\]', '', df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "0ab545a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts['preprocessed'] = df_texts.apply(preprocessing_texts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "b0c43148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts.to_csv('tj_texts_upd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "id": "2ff26d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 298694/298694 [09:57<00:00, 499.89it/s]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "tags = {}\n",
    "for key in tqdm(files):\n",
    "    with open(path + key) as json_file:\n",
    "        data = json.load(json_file)\n",
    "    tags[key] = {}\n",
    "    tags[key]['tag'] = [item['text'] for item in data['result']['badges']]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20523a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntag_set = set()\\nfor key in tags.keys():\\n    if len(tags[key]['tag'])!=0 and tags[key]['tag'][0] not in tag_set:\\n        print(tags[key])\\n        tag_set.add(tags[key]['tag'][0])\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "tag_set = set()\n",
    "for key in tags.keys():\n",
    "    if len(tags[key]['tag'])!=0 and tags[key]['tag'][0] not in tag_set:\n",
    "        print(tags[key])\n",
    "        tag_set.add(tags[key]['tag'][0])\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
